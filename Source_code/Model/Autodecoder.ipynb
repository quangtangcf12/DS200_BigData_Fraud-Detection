{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9775239,"sourceType":"datasetVersion","datasetId":5988050},{"sourceId":12277352,"sourceType":"datasetVersion","datasetId":7736924},{"sourceId":12307856,"sourceType":"datasetVersion","datasetId":7757750},{"sourceId":12317205,"sourceType":"datasetVersion","datasetId":7763807}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"application/vnd.databricks.v1+notebook":{"computePreferences":null,"dashboards":[],"environmentMetadata":{"base_environment":"","environment_version":"1"},"inputWidgetPreferences":null,"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Fraud detectopm","widgets":{}},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle environment - list available datasets\nimport os\nprint(\"Available datasets in /kaggle/input/:\")\nif os.path.exists(\"/kaggle/input/\"):\n    for item in os.listdir(\"/kaggle/input/\"):\n        print(f\"- {item}\")\nelse:\n    print(\"Running locally - /kaggle/input/ not found\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"783cac6d-89ff-4b92-b849-d438e4148f1b","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T04:40:28.954251Z","iopub.execute_input":"2025-07-14T04:40:28.954493Z","iopub.status.idle":"2025-07-14T04:40:28.962147Z","shell.execute_reply.started":"2025-07-14T04:40:28.954472Z","shell.execute_reply":"2025-07-14T04:40:28.961346Z"},"id":"5FeYYgWhjPh5","outputId":"c73742d0-92b7-4791-d325-f5bcf57e631a"},"outputs":[{"name":"stdout","text":"Available datasets in /kaggle/input/:\n- filtered-data\n- transactions-fraud-datasets\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, regexp_replace, to_date, when\nfrom pyspark.sql.types import FloatType\nimport polars as pl\n\n# Core libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# TensorFlow/Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model\n\n# Scikit-learn\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import StandardScaler\n\n\n# PySpark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import pandas_udf\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler as SparkStandardScaler\nfrom pyspark.ml import Pipeline","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4aa3b264-9805-498b-9c65-16ecc6bea6c1","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T04:40:36.080162Z","iopub.execute_input":"2025-07-14T04:40:36.080417Z","iopub.status.idle":"2025-07-14T04:40:50.707069Z","shell.execute_reply.started":"2025-07-14T04:40:36.080397Z","shell.execute_reply":"2025-07-14T04:40:50.706216Z"},"id":"BFX5mB8BjPiB","outputId":"8d479d9a-51c6-4373-a120-4a3f02786a8d"},"outputs":[{"name":"stderr","text":"2025-07-14 04:40:38.499919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752468038.697630      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752468038.754826      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from pyspark import SparkConf\nfrom pyspark.sql import SparkSession\n\n# Stop existing Spark session if any\ntry:\n    spark.stop()\n    print(\"Stopped existing Spark session\")\nexcept:\n    pass\n\n# Optimized Spark configuration\nconf = SparkConf()\\\n    .setAppName(\"FraudDetection\")\\\n    .set(\"spark.sql.shuffle.partitions\", \"200\")\\\n    .set(\"spark.sql.autoBroadcastJoinThreshold\", \"50MB\")\\\n    .set(\"spark.executor.memoryOverhead\", \"4g\")\\\n    .set(\"spark.driver.memory\", \"16g\")\\\n    .set(\"spark.executor.memory\", \"8g\")\\\n    .set(\"spark.memory.fraction\", \"0.6\")\\\n    .set(\"spark.memory.storageFraction\", \"0.4\")\\\n    .set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC -XX:MaxGCPauseMillis=200\")\\\n    .set(\"spark.driver.maxResultSize\", \"4g\")\\\n    .set(\"spark.default.parallelism\", \"200\")\\\n    .set(\"spark.memory.offHeap.enabled\", \"true\")\\\n    .set(\"spark.memory.offHeap.size\", \"4g\")\n\n# Initialize Spark session\nspark = SparkSession.builder.config(conf=conf).getOrCreate()\n\n# Set checkpoint directory\ntry:\n    spark.sparkContext.setCheckpointDir(\"/tmp/spark-checkpoint\")\nexcept:\n    pass\n\n# Verify configuration\nprint(\"Spark session initialized with memory optimization\")\nprint(f\"Spark version: {spark.version}\")\nprint(f\"Driver memory: {spark.conf.get('spark.driver.memory')}\")\nprint(f\"Executor memory: {spark.conf.get('spark.executor.memory')}\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"5ca808db-ab52-4cea-b867-060353738cce","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:34:38.769726Z","iopub.execute_input":"2025-07-14T06:34:38.770149Z","iopub.status.idle":"2025-07-14T06:34:39.890468Z","shell.execute_reply.started":"2025-07-14T06:34:38.770127Z","shell.execute_reply":"2025-07-14T06:34:39.889644Z"},"id":"gbjSLAwdjPiD","outputId":"82b9203d-dfd4-4b96-b708-b171a7eb0fb1"},"outputs":[{"name":"stdout","text":"Stopped existing Spark session\nSpark session initialized with memory optimization\nSpark version: 3.5.5\nDriver memory: 16g\nExecutor memory: 8g\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"# Define file locations for Kaggle environment\ncards = \"/kaggle/input/transactions-fraud-datasets/cards_data.csv\"\nusers = \"/kaggle/input/transactions-fraud-datasets/users_data.csv\"\nfiltered_transactions = \"/kaggle/input/filtered-data/filtered_transactions.csv\"\n\n\nprint(f\"Cards file: {cards}\")\nprint(f\"Users file: {users}\")\nprint(f\"Transactions file: {filtered_transactions}\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b57656bb-b99f-480e-935b-d50c0a0b098f","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:34:42.596066Z","iopub.execute_input":"2025-07-14T06:34:42.596347Z","iopub.status.idle":"2025-07-14T06:34:42.601725Z","shell.execute_reply.started":"2025-07-14T06:34:42.596327Z","shell.execute_reply":"2025-07-14T06:34:42.600709Z"},"id":"vsY_fcT2jPiE","outputId":"fc415891-a324-4c9f-e9b4-0526dc0f80e5"},"outputs":[{"name":"stdout","text":"Cards file: /kaggle/input/transactions-fraud-datasets/cards_data.csv\nUsers file: /kaggle/input/transactions-fraud-datasets/users_data.csv\nTransactions file: /kaggle/input/filtered-data/filtered_transactions.csv\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# Step 1: Load the datasets from cloud storage\ndf_cards = spark.read.csv(cards, header=True, inferSchema=True)\ndf_users = spark.read.csv(users, header=True, inferSchema=True)\ndf_filtered_transactions = spark.read.csv(filtered_transactions, header=True, inferSchema=True)\n\n# Step 2: Preprocess df_cards\ndf_cards = (\n    df_cards.drop(\"card_on_dark_web\")\n    .withColumn(\"credit_limit\", regexp_replace(col(\"credit_limit\"), \"[\\$,]\", \"\").cast(FloatType()))\n    .withColumn(\"acct_open_date\", to_date(col(\"acct_open_date\"), \"MM/yyyy\"))\n    .withColumn(\"PIN_Change_Due\", when(col(\"year_pin_last_changed\") < 2025 - 7, \"Yes\").otherwise(\"No\"))\n)\n\n# Step 3: Preprocess df_users\n# Làm sạch dữ liệu tiền tệ và ép kiểu float\ndf_users = (\n    df_users.withColumn(\"per_capita_income\", regexp_replace(col(\"per_capita_income\"), \"[\\$,]\", \"\").cast(FloatType()))\n    .withColumn(\"yearly_income\", regexp_replace(col(\"yearly_income\"), \"[\\$,]\", \"\").cast(FloatType()))\n    .withColumn(\"total_debt\", regexp_replace(col(\"total_debt\"), \"[\\$,]\", \"\").cast(FloatType()))\n)\n\n# Loại bỏ các dòng có NULL hoặc 0 trong các cột quan trọng\ndf_users = df_users.filter(\n    (col(\"per_capita_income\").isNotNull()) & (col(\"per_capita_income\") > 0) &\n    (col(\"yearly_income\").isNotNull()) & (col(\"yearly_income\") > 0) &\n    (col(\"total_debt\").isNotNull()) & (col(\"total_debt\") > 0)\n)\n\n# Thêm retirement_status\ndf_users = df_users.withColumn(\n    \"retirement_status\", when(col(\"current_age\") >= col(\"retirement_age\"), \"Retired\").otherwise(\"Not Retired\")\n)\n\n# Thêm age_group\ndf_users = df_users.withColumn(\n    \"age_group\",\n    when(col(\"current_age\") <= 30, \"18-30\")\n    .when(col(\"current_age\") <= 45, \"31-45\")\n    .when(col(\"current_age\") <= 60, \"46-60\")\n    .otherwise(\"60+\")\n)\n\n# Tính Debt_to_Income_Ratio\ndf_users = df_users.withColumn(\"Debt_to_Income_Ratio\", col(\"total_debt\") / col(\"yearly_income\"))\n\n# Step 4: Preprocess df_filtered_transactions\ndf_filtered_transactions = df_filtered_transactions.withColumn(\n    \"amount\", regexp_replace(col(\"amount\"), \"[\\$,]\", \"\").cast(FloatType())\n)\n","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"cf925888-08e8-40e8-8099-d311d7dbc121","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:38:46.088817Z","iopub.execute_input":"2025-07-14T06:38:46.089431Z","iopub.status.idle":"2025-07-14T06:38:57.073830Z","shell.execute_reply.started":"2025-07-14T06:38:46.089409Z","shell.execute_reply":"2025-07-14T06:38:57.072953Z"},"id":"Sp_FGnqkjPiF","outputId":"1dc71eda-94d2-4a0d-b558-de2d993d9d98"},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"# Step 5: Show a preview of the preprocessed DataFrames\n\n# Config\npl.Config.set_tbl_rows(10)\npl.Config.set_tbl_cols(30)\npl.Config.set_fmt_str_lengths(80)\npl.Config.set_tbl_width_chars(150)\n\nprint(\"Preview of cards data\")\ndf_cards.show(5, truncate=False)\nprint(\"Preview of users data:\")\ndf_users.show(5, truncate=False)\nprint(\"Preview of filtered transactions:\")\ndf_filtered_transactions.show(5, truncate=False)","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"bf9a0713-75e1-4f2f-a03a-df4ab4f2040b","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:38:59.038841Z","iopub.execute_input":"2025-07-14T06:38:59.039427Z","iopub.status.idle":"2025-07-14T06:38:59.306896Z","shell.execute_reply.started":"2025-07-14T06:38:59.039404Z","shell.execute_reply":"2025-07-14T06:38:59.306351Z"},"id":"euBB-V9LjPiF","outputId":"fb1488af-ae8f-4ceb-a0d3-07b8e77e5471"},"outputs":[{"name":"stdout","text":"Preview of cards data\n+----+---------+----------+---------------+----------------+-------+---+--------+----------------+------------+--------------+---------------------+--------------+\n|id  |client_id|card_brand|card_type      |card_number     |expires|cvv|has_chip|num_cards_issued|credit_limit|acct_open_date|year_pin_last_changed|PIN_Change_Due|\n+----+---------+----------+---------------+----------------+-------+---+--------+----------------+------------+--------------+---------------------+--------------+\n|4524|825      |Visa      |Debit          |4344676511950444|12/2022|623|YES     |2               |24295.0     |2002-09-01    |2008                 |Yes           |\n|2731|825      |Visa      |Debit          |4956965974959986|12/2020|393|YES     |2               |21968.0     |2014-04-01    |2014                 |Yes           |\n|3701|825      |Visa      |Debit          |4582313478255491|02/2024|719|YES     |2               |46414.0     |2003-07-01    |2004                 |Yes           |\n|42  |825      |Visa      |Credit         |4879494103069057|08/2024|693|NO      |1               |12400.0     |2003-01-01    |2012                 |Yes           |\n|4659|825      |Mastercard|Debit (Prepaid)|5722874738736011|03/2009|75 |YES     |1               |28.0        |2008-09-01    |2009                 |Yes           |\n+----+---------+----------+---------------+----------------+-------+---+--------+----------------+------------+--------------+---------------------+--------------+\nonly showing top 5 rows\n\nPreview of users data:\n+----+-----------+--------------+----------+-----------+------+------------------------+--------+---------+-----------------+-------------+----------+------------+----------------+-----------------+---------+--------------------+\n|id  |current_age|retirement_age|birth_year|birth_month|gender|address                 |latitude|longitude|per_capita_income|yearly_income|total_debt|credit_score|num_credit_cards|retirement_status|age_group|Debt_to_Income_Ratio|\n+----+-----------+--------------+----------+-----------+------+------------------------+--------+---------+-----------------+-------------+----------+------------+----------------+-----------------+---------+--------------------+\n|825 |53         |66            |1966      |11         |Female|462 Rose Lane           |34.15   |-117.76  |29278.0          |59696.0      |127613.0  |787         |5               |Not Retired      |46-60    |2.1377144197266147  |\n|1746|53         |68            |1966      |12         |Female|3606 Federal Boulevard  |40.76   |-73.74   |37891.0          |77254.0      |191349.0  |701         |5               |Not Retired      |46-60    |2.4768814559763896  |\n|1718|81         |67            |1938      |11         |Female|766 Third Drive         |34.02   |-117.89  |22681.0          |33483.0      |196.0     |698         |5               |Retired          |60+      |0.005853716811516292|\n|708 |63         |63            |1957      |1          |Female|3 Madison Street        |40.71   |-73.99   |163145.0         |249925.0     |202328.0  |722         |4               |Retired          |60+      |0.809554866459938   |\n|1164|43         |70            |1976      |9          |Male  |9620 Valley Stream Drive|37.76   |-122.44  |53797.0          |109687.0     |183855.0  |675         |1               |Not Retired      |31-45    |1.676178580871024   |\n+----+-----------+--------------+----------+-----------+------+------------------------+--------+---------+-----------------+-------------+----------+------------+----------------+-----------------+---------+--------------------+\nonly showing top 5 rows\n\nPreview of filtered transactions:\n+-------+-------------------+---------+-------+------+-----------+----------+-----------+----+\n|id     |date               |client_id|card_id|amount|merchant_id|card_brand|fraud_label|mcc |\n+-------+-------------------+---------+-------+------+-----------+----------+-----------+----+\n|7475327|2010-01-01 00:01:00|1556     |2972   |-77.0 |59935      |Mastercard|No         |5499|\n|7475328|2010-01-01 00:02:00|561      |4575   |14.57 |67570      |Mastercard|No         |5311|\n|7475329|2010-01-01 00:02:00|1129     |102    |80.0  |27092      |Mastercard|No         |4829|\n|7475332|2010-01-01 00:06:00|848      |3915   |46.41 |13051      |Visa      |No         |5813|\n|7475333|2010-01-01 00:07:00|1807     |165    |4.81  |20519      |Mastercard|No         |5942|\n+-------+-------------------+---------+-------+------+-----------+----------+-----------+----+\nonly showing top 5 rows\n\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"# Step 6: Count rows and confirm we’re done\n# We’ll count the rows in each DataFrame to see what we’re working with\ncards_count = df_cards.count()\nusers_count = df_users.count()\ntransactions_count = df_filtered_transactions.count()\nprint(f\"Cards DataFrame has {cards_count} rows\")\nprint(f\"Users DataFrame has {users_count} rows\")\nprint(f\"Transactions DataFrame has {transactions_count} rows\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"428f9e12-ef36-47c5-9a22-cd4aa0fa7c47","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:39:03.311552Z","iopub.execute_input":"2025-07-14T06:39:03.312106Z","iopub.status.idle":"2025-07-14T06:39:05.847139Z","shell.execute_reply.started":"2025-07-14T06:39:03.312082Z","shell.execute_reply":"2025-07-14T06:39:05.846322Z"},"id":"zzxL7bS7jPiH","outputId":"0690dddd-9c60-4d9a-a13c-7dfd9d668eda"},"outputs":[{"name":"stderr","text":"[Stage 21:================================================================>         (125 + 4) / 144]\r","output_type":"stream"},{"name":"stdout","text":"Cards DataFrame has 6146 rows\nUsers DataFrame has 1887 rows\nTransactions DataFrame has 8914963 rows\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"df_filtered_transactions.groupBy(\"fraud_label\").count().show()","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"0878b081-402f-4b06-a3a8-3340c70ddeaf","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:39:06.994174Z","iopub.execute_input":"2025-07-14T06:39:06.994444Z","iopub.status.idle":"2025-07-14T06:39:14.012830Z","shell.execute_reply.started":"2025-07-14T06:39:06.994425Z","shell.execute_reply":"2025-07-14T06:39:14.011890Z"},"id":"QVpNcd9RjPiI","outputId":"72cbb543-bae4-4762-d083-80c0b1da37a0"},"outputs":[{"name":"stderr","text":"[Stage 24:=========================================================================>(143 + 1) / 144]\r","output_type":"stream"},{"name":"stdout","text":"+-----------+-------+\n|fraud_label|  count|\n+-----------+-------+\n|         No|8901631|\n|        Yes|  13332|\n+-----------+-------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"import mlflow\nimport os\n\ntry:\n    os.makedirs(\"/kaggle/working/mlruns\", exist_ok=True)\n    mlflow.set_tracking_uri(\"file:///kaggle/working/mlruns\")\n    print(\"MLflow tracking URI set to /kaggle/working/mlruns\")\nexcept:\n    mlflow.set_tracking_uri(\"file:./mlruns\")\n    print(\"MLflow tracking URI set to ./mlruns\")\n\nprint(\"MLflow setup completed for Kaggle environment\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c4feb943-12d6-4589-8053-09d3f675c08e","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:39:14.014226Z","iopub.execute_input":"2025-07-14T06:39:14.014690Z","iopub.status.idle":"2025-07-14T06:39:14.021750Z","shell.execute_reply.started":"2025-07-14T06:39:14.014666Z","shell.execute_reply":"2025-07-14T06:39:14.020142Z"},"id":"XekGKVkJjPiJ","outputId":"ab4b1ede-4e47-40e1-d565-2710869ecd99"},"outputs":[{"name":"stdout","text":"MLflow tracking URI set to /kaggle/working/mlruns\nMLflow setup completed for Kaggle environment\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"from pyspark.sql.functions import col, udf\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.types import FloatType\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pyspark.ml.feature import VectorAssembler, MinMaxScaler\nimport mlflow\nimport mlflow.keras\n","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d1c38272-295c-4486-9842-8cdd302ac38c","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:39:24.172745Z","iopub.execute_input":"2025-07-14T06:39:24.173057Z","iopub.status.idle":"2025-07-14T06:39:24.178596Z","shell.execute_reply.started":"2025-07-14T06:39:24.173035Z","shell.execute_reply":"2025-07-14T06:39:24.177745Z"},"id":"-hDUK1HLjPiK"},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# Data joining\ntransactions = df_filtered_transactions.alias(\"transactions\")\ncards = df_cards.alias(\"cards\")\nusers = df_users.alias(\"users\")\n\ndf_temp = transactions.join(\n    cards,\n    transactions[\"card_id\"] == cards[\"id\"],\n    \"left\"\n).select(\n    transactions[\"id\"].alias(\"transaction_id\"),\n    transactions[\"client_id\"],\n    transactions[\"amount\"],\n    transactions[\"fraud_label\"],\n    transactions[\"mcc\"],\n    transactions[\"card_brand\"],\n    cards[\"credit_limit\"],\n    cards[\"card_type\"]\n)\n\ntransactions = df_filtered_transactions.alias(\"transactions\")\ncards = df_cards.alias(\"cards\")\nusers = df_users.alias(\"users\")\n\ndf_temp = transactions.join(\n    cards,\n    transactions[\"card_id\"] == cards[\"id\"],\n    \"left\"\n).select(\n    transactions[\"id\"].alias(\"transaction_id\"),\n    transactions[\"client_id\"],\n    transactions[\"amount\"],\n    transactions[\"fraud_label\"],\n    transactions[\"mcc\"],\n    transactions[\"card_brand\"],\n    cards[\"credit_limit\"],\n    cards[\"card_type\"]\n)\n\ndf_combined = df_temp.join(\n    users,\n    df_temp[\"client_id\"] == users[\"id\"],\n    \"left\"\n).select(\n    df_temp[\"transaction_id\"],\n    df_temp[\"client_id\"],\n    df_temp[\"amount\"],\n    df_temp[\"fraud_label\"],\n    df_temp[\"mcc\"],\n    df_temp[\"credit_limit\"],\n    df_temp['card_brand'],\n    df_temp[\"card_type\"],\n    users[\"current_age\"],\n    users[\"per_capita_income\"],\n    users[\"yearly_income\"],\n    users[\"total_debt\"],\n    users[\"Debt_to_Income_Ratio\"],\n    users[\"credit_score\"]\n)","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"55464644-50cb-4cd7-8354-b6b227100dfa","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:03.951889Z","iopub.execute_input":"2025-07-14T06:40:03.952188Z","iopub.status.idle":"2025-07-14T06:40:04.011212Z","shell.execute_reply.started":"2025-07-14T06:40:03.952168Z","shell.execute_reply":"2025-07-14T06:40:04.010412Z"},"id":"ubfedYFkjPiK"},"outputs":[],"execution_count":89},{"cell_type":"code","source":"from pyspark.ml.feature import StringIndexer\n\n# Encode categorical feature\nindexer_card_type = StringIndexer(inputCol=\"card_type\", outputCol=\"card_type_indexed\", handleInvalid=\"keep\")\ndf_combined = indexer_card_type.fit(df_combined).transform(df_combined)\ndf_combined = df_combined.drop(\"card_type\").withColumnRenamed(\"card_type_indexed\", \"card_type\")\nindexer_card_brand = StringIndexer(inputCol=\"card_brand\", outputCol=\"card_brand_indexed\", handleInvalid=\"keep\")\ndf_combined = indexer_card_brand.fit(df_combined).transform(df_combined)\ndf_combined = df_combined.drop(\"card_brand\").withColumnRenamed(\"card_brand_indexed\", \"card_brand\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:08.313986Z","iopub.execute_input":"2025-07-14T06:40:08.314271Z","iopub.status.idle":"2025-07-14T06:40:26.198134Z","shell.execute_reply.started":"2025-07-14T06:40:08.314253Z","shell.execute_reply":"2025-07-14T06:40:26.197240Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"df_combined = df_combined.withColumn(\n    \"fraud_label\",\n    when(col(\"fraud_label\") == \"Yes\", 1).otherwise(0)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:41.710984Z","iopub.execute_input":"2025-07-14T06:40:41.711659Z","iopub.status.idle":"2025-07-14T06:40:41.726418Z","shell.execute_reply.started":"2025-07-14T06:40:41.711637Z","shell.execute_reply":"2025-07-14T06:40:41.725619Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"df_combined.printSchema()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:40:44.500870Z","iopub.execute_input":"2025-07-14T06:40:44.501175Z","iopub.status.idle":"2025-07-14T06:40:44.505860Z","shell.execute_reply.started":"2025-07-14T06:40:44.501155Z","shell.execute_reply":"2025-07-14T06:40:44.505297Z"}},"outputs":[{"name":"stdout","text":"root\n |-- transaction_id: integer (nullable = true)\n |-- client_id: integer (nullable = true)\n |-- amount: float (nullable = true)\n |-- fraud_label: integer (nullable = false)\n |-- mcc: integer (nullable = true)\n |-- credit_limit: float (nullable = true)\n |-- current_age: integer (nullable = true)\n |-- per_capita_income: float (nullable = true)\n |-- yearly_income: float (nullable = true)\n |-- total_debt: float (nullable = true)\n |-- Debt_to_Income_Ratio: double (nullable = true)\n |-- credit_score: integer (nullable = true)\n |-- card_type: double (nullable = false)\n |-- card_brand: double (nullable = false)\n\n","output_type":"stream"}],"execution_count":92},{"cell_type":"code","source":"from pyspark.sql.functions import col\n# Set experiment name cho Kaggle\nmlflow.set_experiment('Autodecoder_model')\n\nfeatures = [\"amount\", \"current_age\", \"per_capita_income\", \"yearly_income\", \"total_debt\", \"Debt_to_Income_Ratio\", \"credit_limit\",\"credit_score\"]\ndf_cleaned = df_combined.dropna(subset=features)\nprint(f\"Dataset combined successfully!\")\nprint(f\"Total features: {len(features)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:43:33.131659Z","iopub.execute_input":"2025-07-14T06:43:33.132444Z","iopub.status.idle":"2025-07-14T06:43:33.147624Z","shell.execute_reply.started":"2025-07-14T06:43:33.132420Z","shell.execute_reply":"2025-07-14T06:43:33.146905Z"}},"outputs":[{"name":"stdout","text":"Dataset combined successfully!\nTotal features: 8\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"# Vector hóa đặc trưng\nassembler = VectorAssembler(inputCols=features, outputCol=\"raw_features\")\n# Chuẩn hóa Min-Max\nscaler = MinMaxScaler(inputCol=\"raw_features\", outputCol=\"features\")\n# Define pipeline\npipeline = Pipeline(stages=[assembler, scaler])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:47:01.759381Z","iopub.execute_input":"2025-07-14T06:47:01.759976Z","iopub.status.idle":"2025-07-14T06:47:01.770707Z","shell.execute_reply.started":"2025-07-14T06:47:01.759952Z","shell.execute_reply":"2025-07-14T06:47:01.769960Z"},"id":"0qHVAeVxjPiL"},"outputs":[],"execution_count":99},{"cell_type":"code","source":"# Áp dụng pipeline xử lý dữ liệu\nprocessed_data = pipeline.fit(df_cleaned).transform(df_cleaned)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:47:03.190001Z","iopub.execute_input":"2025-07-14T06:47:03.190555Z","iopub.status.idle":"2025-07-14T06:47:20.389574Z","shell.execute_reply.started":"2025-07-14T06:47:03.190535Z","shell.execute_reply":"2025-07-14T06:47:20.388276Z"},"id":"yuFuHdmkjPiM","outputId":"7422d038-a4a6-468b-b4b3-8233d2f8218b"},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"from pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import ArrayType, DoubleType\nimport numpy as np\n\n# UDF để chuyển vector Spark thành list\ndef vec_to_array(v):\n    return v.toArray().tolist()\n\nvec_to_array_udf = udf(vec_to_array, ArrayType(DoubleType()))\n\n# Tách dữ liệu thành normal và fraud\nfraud_data = processed_data.filter(col(\"fraud_label\") == 1)\nnormal_data = processed_data.filter(col(\"fraud_label\") == 0)\n\n# Kiểm tra số lượng dữ liệu trước khi chia\nprint(f\"Số lượng giao dịch normal: {normal_data.count()}\")\nprint(f\"Số lượng giao dịch fraud: {fraud_data.count()}\")\n\n# Chia dữ liệu normal thành train và test\ntrain_normal, temp_normal = normal_data.randomSplit([0.8, 0.2], seed=42)\n\n# Chia fraud chỉ lấy test\n_, test_fraud = fraud_data.randomSplit([0.2, 0.8], seed=42)\n\n# Tạo tập test từ normal test và fraud test\ntest_normal = temp_normal  # Phần 20% normal dành cho test\ntest_data = test_normal.union(test_fraud)\n\n# Thêm cột features_array\ntrain_normal = train_normal.withColumn(\"features_array\", vec_to_array_udf(col(\"features\")))\ntest_data = test_data.withColumn(\"features_array\", vec_to_array_udf(col(\"features\")))\n\n# Chuyển train_normal thành X_train (kiểm tra kỹ)\nif train_normal.count() == 0:\n    raise ValueError(\"Tập huấn luyện trống sau khi chia. Hãy kiểm tra tỷ lệ chia và dữ liệu đầu vào.\")\n\ntrain_features = train_normal.select(\"features_array\").rdd.map(lambda row: row[\"features_array\"]).collect()\nX_train = np.vstack(train_features)\n\n# Chuyển test_data thành X_test, y_test\ntest_features = test_data.select(\"features_array\").rdd.map(lambda row: row[\"features_array\"]).collect()\ntest_labels = test_data.select(\"fraud_label\").rdd.map(lambda row: row[\"fraud_label\"]).collect()\nX_test = np.vstack(test_features)\ny_test = np.array(test_labels)\n\n# Kiểm tra kết quả\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")\nprint(f\"Số lượng fraud trong tập test: {np.sum(y_test)} / {len(y_test)}\")\nprint(f\"Số lượng mẫu huấn luyện: {len(X_train)}\")","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"967fd4bd-ea28-4d9e-a7e4-c67a11fcce1d","showTitle":false,"tableResultSettingsMap":{},"title":""},"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:47:20.391223Z","iopub.execute_input":"2025-07-14T06:47:20.391559Z","iopub.status.idle":"2025-07-14T06:52:38.576054Z","shell.execute_reply.started":"2025-07-14T06:47:20.391534Z","shell.execute_reply":"2025-07-14T06:52:38.575348Z"},"id":"Ivh2yUiVjPiN","outputId":"076c71fa-d777-4d85-d081-779d4276ae20"},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Số lượng giao dịch normal: 8403654\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Số lượng giao dịch fraud: 12470\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"X_train shape: (6721596, 8)\nX_test shape: (1692001, 8)\ny_test shape: (1692001,)\nSố lượng fraud trong tập test: 9943 / 1692001\nSố lượng mẫu huấn luyện: 6721596\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"def build_autoencoder(input_dim):\n    input_layer = Input(shape=(input_dim,))\n\n    # Encoder với regularization\n    encoder = Dense(256, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l1(10e-5))(input_layer)\n    encoder = Dense(128, activation=\"relu\")(encoder)\n    encoder = Dense(64, activation=\"relu\")(encoder)\n\n    # Bottleneck\n    bottleneck = Dense(32, activation=\"relu\")(encoder)\n\n    # Decoder\n    decoder = Dense(64, activation=\"relu\")(bottleneck)\n    decoder = Dense(128, activation=\"relu\")(decoder)\n    decoder = Dense(256, activation=\"relu\")(decoder)\n    output_layer = Dense(input_dim, activation=\"linear\")(decoder)\n\n    return Model(inputs=input_layer, outputs=output_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:52:38.589014Z","iopub.execute_input":"2025-07-14T06:52:38.589243Z","iopub.status.idle":"2025-07-14T06:52:38.594669Z","shell.execute_reply.started":"2025-07-14T06:52:38.589225Z","shell.execute_reply":"2025-07-14T06:52:38.593970Z"},"id":"Xwecv_N7jPiN"},"outputs":[],"execution_count":102},{"cell_type":"code","source":"input_dim = X_train.shape[1]\nautoencoder = build_autoencoder(input_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:52:38.595304Z","iopub.execute_input":"2025-07-14T06:52:38.595478Z","iopub.status.idle":"2025-07-14T06:52:38.669605Z","shell.execute_reply.started":"2025-07-14T06:52:38.595464Z","shell.execute_reply":"2025-07-14T06:52:38.669137Z"},"id":"ktP5EoqGjPiN","outputId":"fd030ecc-9720-4d1d-8f8f-634f0a85ecf4"},"outputs":[],"execution_count":103},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.metrics import (\n    confusion_matrix, ConfusionMatrixDisplay, classification_report,\n    f1_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n)\nimport mlflow\nimport os\n\n# ===== Huấn luyện Autoencoder với MLflow =====\nwith mlflow.start_run():\n    mlflow.log_param(\"input_dim\", input_dim)\n    mlflow.log_param(\"epochs\", 200)\n    mlflow.log_param(\"batch_size\", 64)\n    mlflow.log_param(\"patience\", 10)\n    mlflow.log_param(\"min_delta\", 0.001)\n\n    autoencoder.compile(optimizer='adam', loss='mse')\n\n    early_stopping = EarlyStopping(monitor='val_loss', patience=10, min_delta=0.001, restore_best_weights=True, verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n    checkpoint = ModelCheckpoint(filepath='best_autoencoder.h5', monitor='val_loss', save_best_only=True, verbose=1)\n\n    history = autoencoder.fit(\n        X_train, X_train,\n        epochs=200,\n        batch_size=64,\n        shuffle=True,\n        validation_split=0.1,\n        verbose=1,\n        callbacks=[early_stopping, reduce_lr, checkpoint]\n    )\n\n    mlflow.log_metric(\"actual_epochs\", len(history.history['loss']))\n    mlflow.log_metric(\"best_val_loss\", min(history.history['val_loss']))\n    mlflow.log_metric(\"best_train_loss\", min(history.history['loss']))\n\n    # === Đường cong loss + LR\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    ax1.plot(history.history['loss'], label='Training Loss')\n    ax1.plot(history.history['val_loss'], label='Validation Loss')\n    ax1.set_title('Model Loss')\n    ax1.set_xlabel('Epoch'); ax1.set_ylabel('Loss'); ax1.legend(); ax1.grid(True)\n\n    if 'lr' in history.history:\n        ax2.plot(history.history['lr'], label='Learning Rate')\n        ax2.set_title('Learning Rate Schedule')\n        ax2.set_xlabel('Epoch'); ax2.set_ylabel('Learning Rate')\n        ax2.set_yscale('log'); ax2.legend(); ax2.grid(True)\n    else:\n        ax2.text(0.5, 0.5, 'No LR data available', ha='center', va='center')\n        ax2.set_title('Learning Rate Schedule')\n\n    plt.tight_layout()\n    mlflow.log_figure(fig, \"training_curves.png\")\n    plt.close(fig)\n\n    # ===== Hàm tính lỗi khôi phục =====\n    def calculate_reconstruction_error(data):\n        reconstructions = autoencoder.predict(data)\n        return np.mean(np.power(data - reconstructions, 2), axis=1)\n\n    train_errors = calculate_reconstruction_error(X_train)\n    test_errors = calculate_reconstruction_error(X_test)\n\n    # ===== Threshold từ quantile 0.99 trên tập train =====\n    threshold = np.quantile(train_errors, 0.99)\n    mlflow.log_metric(\"threshold\", float(threshold))\n\n    # ===== Dự đoán và đánh giá =====\n    y_pred = (test_errors > threshold).astype(int)\n    cm = confusion_matrix(y_test, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n    mlflow.log_metrics({\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"true_positives\": tp,\n        \"false_positives\": fp,\n        \"true_negatives\": tn,\n        \"false_negatives\": fn\n    })\n\n\n    # ===== Classification report =====\n    report = classification_report(y_test, y_pred, target_names=[\"Normal\", \"Fraud\"], output_dict=True)\n    mlflow.log_dict(report, \"classification_report.json\")\n    mlflow.log_dict(history.history, \"training_history.json\")\n    mlflow.keras.log_model(autoencoder, \"autoencoder_model\")\n\n    print(f\"Training completed after {len(history.history['loss'])} epochs\")\n    print(f\"Best validation loss: {min(history.history['val_loss']):.6f}\")\n    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n    print(f\"Fraud Detection Rate: {recall:.2%}\")\n\n# ===== Lưu mô hình để dùng sau =====\nautoencoder.save(\"autoencoder_fraud_model.h5\")\nprint(\"Model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:52:38.671092Z","iopub.execute_input":"2025-07-14T06:52:38.671500Z","iopub.status.idle":"2025-07-14T07:43:04.985173Z","shell.execute_reply.started":"2025-07-14T06:52:38.671485Z","shell.execute_reply":"2025-07-14T07:43:04.984410Z"},"id":"19knQVpHjPiN","outputId":"3e77bc3d-01d7-42c3-f433-7cc33554d403"},"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4506e-04\nEpoch 1: val_loss improved from inf to 0.00013, saving model to best_autoencoder.h5\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2ms/step - loss: 6.4506e-04 - val_loss: 1.2797e-04 - learning_rate: 0.0010\nEpoch 2/200\n\u001b[1m94510/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4353e-04\nEpoch 2: val_loss did not improve from 0.00013\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2ms/step - loss: 1.4353e-04 - val_loss: 3.2996e-04 - learning_rate: 0.0010\nEpoch 3/200\n\u001b[1m94515/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4160e-04\nEpoch 3: val_loss improved from 0.00013 to 0.00012, saving model to best_autoencoder.h5\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2ms/step - loss: 1.4159e-04 - val_loss: 1.1872e-04 - learning_rate: 0.0010\nEpoch 4/200\n\u001b[1m94511/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3889e-04\nEpoch 4: val_loss improved from 0.00012 to 0.00011, saving model to best_autoencoder.h5\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2ms/step - loss: 1.3889e-04 - val_loss: 1.1379e-04 - learning_rate: 0.0010\nEpoch 5/200\n\u001b[1m94522/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4861e-04\nEpoch 5: val_loss did not improve from 0.00011\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 3ms/step - loss: 1.4861e-04 - val_loss: 1.1401e-04 - learning_rate: 0.0010\nEpoch 6/200\n\u001b[1m94515/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5725e-04\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 6: val_loss did not improve from 0.00011\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 3ms/step - loss: 1.5725e-04 - val_loss: 1.2461e-04 - learning_rate: 0.0010\nEpoch 7/200\n\u001b[1m94508/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0006e-04\nEpoch 7: val_loss improved from 0.00011 to 0.00007, saving model to best_autoencoder.h5\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 3ms/step - loss: 1.0006e-04 - val_loss: 7.4372e-05 - learning_rate: 5.0000e-04\nEpoch 8/200\n\u001b[1m94519/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7519e-05\nEpoch 8: val_loss did not improve from 0.00007\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 3ms/step - loss: 9.7519e-05 - val_loss: 7.9446e-05 - learning_rate: 5.0000e-04\nEpoch 9/200\n\u001b[1m94511/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7974e-05\nEpoch 9: val_loss did not improve from 0.00007\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2ms/step - loss: 9.7974e-05 - val_loss: 1.0431e-04 - learning_rate: 5.0000e-04\nEpoch 10/200\n\u001b[1m94502/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8526e-05\nEpoch 10: val_loss did not improve from 0.00007\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2ms/step - loss: 9.8526e-05 - val_loss: 9.8789e-05 - learning_rate: 5.0000e-04\nEpoch 11/200\n\u001b[1m94504/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7743e-05\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 11: val_loss did not improve from 0.00007\n\u001b[1m94523/94523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2ms/step - loss: 9.7743e-05 - val_loss: 3.2006e-04 - learning_rate: 5.0000e-04\nEpoch 11: early stopping\nRestoring model weights from the end of the best epoch: 1.\n\u001b[1m210050/210050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1ms/step\n\u001b[1m52876/52876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1ms/step\n","output_type":"stream"},{"name":"stderr","text":"2025/07/14 07:42:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n2025/07/14 07:42:56 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n\u001b[31m2025/07/14 07:43:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Training completed after 11 epochs\nBest validation loss: 0.000074\nPrecision: 0.0400, Recall: 0.0699, F1: 0.0509\nFraud Detection Rate: 6.99%\nModel saved successfully!\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"# ===== IMPORT =====\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import load_model\nfrom sklearn.metrics import (\n    confusion_matrix, ConfusionMatrixDisplay, classification_report,\n    f1_score, precision_score, recall_score, roc_curve, auc, precision_recall_curve\n)\nimport zipfile\nimport os\nfrom IPython.display import FileLink\n\n# ===== Load mô hình =====\nautoencoder = load_model(\"/kaggle/working/autoencoder_fraud_model.h5\", compile=False)\nautoencoder.compile(optimizer='adam', loss='mse')\nprint(\"Mô hình đã load và compile thành công.\")\n\n# ===== Hàm tính reconstruction error =====\ndef calculate_reconstruction_error(data):\n    reconstructions = autoencoder.predict(data)\n    return np.mean(np.power(data - reconstructions, 2), axis=1)\n\n# ===== Tính lỗi khôi phục =====\ntrain_errors = calculate_reconstruction_error(X_train)\ntest_errors = calculate_reconstruction_error(X_test)\n\n# ===== Chọn threshold theo quantile (ví dụ 0.99) =====\nbest_threshold = np.quantile(train_errors, 0.99)\nprint(f\"Threshold chọn theo phân phối train_error (99th percentile): {best_threshold:.6f}\")\n\n# ===== Phân loại với ngưỡng đã chọn =====\ny_pred = (test_errors > best_threshold).astype(int)\n\n# ===== Tính toán và in báo cáo =====\nf1 = f1_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\n\nprint(\"Kết quả phân loại:\")\nprint(f\"- F1-score:  {f1:.4f}\")\nprint(f\"- Precision: {precision:.4f}\")\nprint(f\"- Recall:    {recall:.4f}\")\n\n# ===== Vẽ confusion matrix =====\ncm = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(10, 8))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Fraud\"])\ndisp.plot(ax=ax)\nplt.title(\"Confusion Matrix\")\nfig.savefig(\"confusion_matrix.png\")\nplt.close(fig)\n\n# ===== Phân phối reconstruction error =====\nfig, ax = plt.subplots(figsize=(10, 6))\nax.hist(train_errors, bins=50, alpha=0.5, label=\"Train (Normal)\")\nax.hist(test_errors[y_test == 0], bins=50, alpha=0.5, label=\"Test (Normal)\")\nax.hist(test_errors[y_test == 1], bins=50, alpha=0.5, label=\"Test (Fraud)\")\nax.axvline(best_threshold, color='r', linestyle='--', linewidth=2, label=f\"Threshold: {best_threshold:.4f}\")\nax.set_title(\"Reconstruction Error Distribution\")\nax.set_xlabel(\"Reconstruction Error\")\nax.set_ylabel(\"Frequency\")\nax.legend()\nfig.savefig(\"error_distribution.png\")\nplt.close(fig)\n\n# ===== ROC Curve =====\nfpr, tpr, _ = roc_curve(y_test, test_errors)\nroc_auc = auc(fpr, tpr)\n\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\nax.plot([0, 1], [0, 1], linestyle='--', color='gray')\nax.set_title(\"ROC Curve\")\nax.set_xlabel(\"False Positive Rate\")\nax.set_ylabel(\"True Positive Rate (Recall)\")\nax.legend()\nax.grid(True)\nfig.savefig(\"roc_curve.png\")\nplt.close(fig)\n\n# ===== Precision-Recall Curve =====\nprecision_vals, recall_vals, _ = precision_recall_curve(y_test, test_errors)\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(recall_vals, precision_vals, color='green')\nax.set_title(\"Precision-Recall Curve\")\nax.set_xlabel(\"Recall\")\nax.set_ylabel(\"Precision\")\nax.grid(True)\nfig.savefig(\"pr_curve.png\")\nplt.close(fig)\n\n# ===== Báo cáo phân loại chi tiết =====\nreport = classification_report(y_test, y_pred, target_names=[\"Normal\", \"Fraud\"])\nwith open(\"classification_report.txt\", \"w\") as f:\n    f.write(report)\n\n# ===== Nén toàn bộ đầu ra =====\nwith zipfile.ZipFile(\"fraud_detection_outputs.zip\", \"w\") as zipf:\n    for fname in [\n        \"confusion_matrix.png\",\n        \"error_distribution.png\",\n        \"roc_curve.png\",\n        \"pr_curve.png\",\n        \"classification_report.txt\"\n    ]:\n        if os.path.exists(fname):\n            zipf.write(fname)\n\n# ===== Link tải file zip kết quả =====\nFileLink(\"fraud_detection_outputs.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T07:43:48.706277Z","iopub.execute_input":"2025-07-14T07:43:48.706988Z","iopub.status.idle":"2025-07-14T07:51:22.480573Z","shell.execute_reply.started":"2025-07-14T07:43:48.706957Z","shell.execute_reply":"2025-07-14T07:51:22.479909Z"},"id":"-7hdQhHijPiO","outputId":"6010a663-b1eb-4a87-827f-22299663b515"},"outputs":[{"name":"stdout","text":"Mô hình đã load và compile thành công.\n\u001b[1m210050/210050\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1ms/step\n\u001b[1m52876/52876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1ms/step\nThreshold chọn theo phân phối train_error (99th percentile): 0.000345\nKết quả phân loại:\n- F1-score:  0.0509\n- Precision: 0.0400\n- Recall:    0.0699\n","output_type":"stream"},{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fraud_detection_outputs.zip","text/html":"<a href='fraud_detection_outputs.zip' target='_blank'>fraud_detection_outputs.zip</a><br>"},"metadata":{}}],"execution_count":106}]}